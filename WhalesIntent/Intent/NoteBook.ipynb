{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce14ee3e",
   "metadata": {},
   "source": [
    "### ETH Whale Activity ML Pipeline\n",
    "\n",
    "- Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6e9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è imbalanced-learn not installed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report, confusion_matrix, make_scorer\n",
    ")\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    HAS_IMBLEARN = True\n",
    "except ImportError:\n",
    "    HAS_IMBLEARN = False\n",
    "    print(\"‚ö†Ô∏è imbalanced-learn not installed\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGBOOST = True\n",
    "except ImportError:\n",
    "    HAS_XGBOOST = False\n",
    "    print(\"‚ö†Ô∏è XGBoost not installed\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6646b",
   "metadata": {},
   "source": [
    "- Loading and Configuring Environmental Varriables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc97b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DUNE_API_KEY = os.getenv(\"DUNE_WHALES_API\")\n",
    "COINGECKO_API_KEY = os.getenv(\"COINGECKO_API_KEY\")\n",
    "\n",
    "PRICE_CACHE_DIR = \"data/price_cache\"\n",
    "os.makedirs(PRICE_CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "QUERIES = {\n",
    "    \"whales\": (\"6395391\", \"dune_whales_cache.json\", \"whale_ml_ready.csv\"),\n",
    "    \"market_intent\": (\"6385600\", \"dune_intent_cache.json\", \"market_intent_ml_ready.csv\")\n",
    "}\n",
    "REQUEST_DELAY = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6edaa8",
   "metadata": {},
   "source": [
    "- Data Collection - Fetch Whale Data from Dune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f6dcb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dune_incremental(query_id, cache_file):\n",
    "    \n",
    "    headers = {\"x-dune-api-key\": DUNE_API_KEY}\n",
    "    today = pd.Timestamp(datetime.utcnow().date())\n",
    "    \n",
    "    # Load cache\n",
    "    df_cached, fetch_start = pd.DataFrame(), None\n",
    "    if os.path.exists(cache_file):\n",
    "        cache = json.load(open(cache_file))\n",
    "        df_cached = pd.DataFrame(cache[\"data\"])\n",
    "        df_cached[\"block_date\"] = pd.to_datetime(df_cached[\"block_date\"])\n",
    "        fetch_start = pd.to_datetime(cache[\"last_block_date\"]) + timedelta(days=1)\n",
    "        \n",
    "        if fetch_start >= today:\n",
    "            print(f\"‚úÖ {cache_file} up-to-date\")\n",
    "            return df_cached\n",
    "        print(f\"üîÑ Fetching {fetch_start.date()} ‚Üí {today.date()}\")\n",
    "    else:\n",
    "        print(f\"üÜï Full fetch for {cache_file}\")\n",
    "    \n",
    "    # Execute query\n",
    "    payload = {\"query_parameters\": [{\"name\": \"start_date\", \"type\": \"date\", \"value\": fetch_start.strftime(\"%Y-%m-%d\")}]} if fetch_start is not None else {}\n",
    "    exec_id = requests.post(f\"https://api.dune.com/api/v1/query/{query_id}/execute\", \n",
    "                           headers=headers, json=payload).json()[\"execution_id\"]\n",
    "    \n",
    "    # Poll until complete\n",
    "    while True:\n",
    "        status = requests.get(f\"https://api.dune.com/api/v1/execution/{exec_id}/status\", \n",
    "                            headers=headers).json()[\"state\"]\n",
    "        if status == \"QUERY_STATE_COMPLETED\": break\n",
    "        if status == \"QUERY_STATE_FAILED\": raise RuntimeError(\"Query failed\")\n",
    "        time.sleep(10)\n",
    "    \n",
    "    # Get results\n",
    "    df_new = pd.DataFrame(requests.get(f\"https://api.dune.com/api/v1/execution/{exec_id}/results\", \n",
    "                                       headers=headers).json()[\"result\"][\"rows\"])\n",
    "    \n",
    "    if df_new.empty:\n",
    "        return df_cached\n",
    "    \n",
    "    df_new[\"block_date\"] = pd.to_datetime(df_new[\"block_date\"])\n",
    "    df_all = pd.concat([df_cached, df_new[df_new[\"block_date\"] < today]], \n",
    "                      ignore_index=True).drop_duplicates(\"block_date\", keep=\"last\").sort_values(\"block_date\")\n",
    "    \n",
    "    # Save cache\n",
    "    json.dump({\"last_block_date\": df_all[\"block_date\"].max().strftime(\"%Y-%m-%d\"),\n",
    "               \"data\": json.loads(df_all.to_json(orient=\"records\", date_format=\"iso\"))}, \n",
    "              open(cache_file, \"w\"))\n",
    "    \n",
    "    print(f\"‚úÖ {cache_file} updated ({len(df_all)} rows)\")\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b84334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING DUNE DATA\n",
      "============================================================\n",
      "\n",
      "WHALES\n",
      "----------------------------------------\n",
      "‚úÖ dune_whales_cache.json up-to-date\n",
      "üíæ Saved to whale_ml_ready.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MARKET_INTENT\n",
      "----------------------------------------\n",
      "‚úÖ dune_intent_cache.json up-to-date\n",
      "üíæ Saved to market_intent_ml_ready.csv\n",
      "\n",
      "‚úÖ Dune Data Loaded:\n",
      "   ‚Ä¢ Whales: 1095 rows\n",
      "   ‚Ä¢ Market Intent: 1095 rows\n",
      "\n",
      "üìä Whales Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_date</th>\n",
       "      <th>deposit_tx_count</th>\n",
       "      <th>deposit_withdrawal_ratio</th>\n",
       "      <th>exchange_volume_ratio</th>\n",
       "      <th>mega_whale_ratio</th>\n",
       "      <th>mega_whale_tx_count</th>\n",
       "      <th>mega_whale_volume_eth</th>\n",
       "      <th>net_flow_ma7</th>\n",
       "      <th>non_exchange_ratio</th>\n",
       "      <th>non_exchange_tx_count</th>\n",
       "      <th>non_exchange_volume_eth</th>\n",
       "      <th>std_whale_tx_size_eth</th>\n",
       "      <th>whale_exchange_deposits_eth</th>\n",
       "      <th>whale_exchange_withdrawals_eth</th>\n",
       "      <th>whale_net_exchange_flow_eth</th>\n",
       "      <th>whale_tx_count</th>\n",
       "      <th>whale_volume_eth</th>\n",
       "      <th>withdrawal_tx_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>11</td>\n",
       "      <td>1.5554</td>\n",
       "      <td>0.2899</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>36</td>\n",
       "      <td>108354.7154</td>\n",
       "      <td>-7203.9190</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>24</td>\n",
       "      <td>81206.9408</td>\n",
       "      <td>3279.562931</td>\n",
       "      <td>20175.0838</td>\n",
       "      <td>12971.1648</td>\n",
       "      <td>-7203.9190</td>\n",
       "      <td>42</td>\n",
       "      <td>114353.1894</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>10</td>\n",
       "      <td>4.4874</td>\n",
       "      <td>0.6327</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>36</td>\n",
       "      <td>147540.1401</td>\n",
       "      <td>-33266.8544</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>18</td>\n",
       "      <td>54184.9701</td>\n",
       "      <td>8106.493990</td>\n",
       "      <td>76342.4799</td>\n",
       "      <td>17012.6900</td>\n",
       "      <td>-59329.7899</td>\n",
       "      <td>36</td>\n",
       "      <td>147540.1401</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>50</td>\n",
       "      <td>196152.9223</td>\n",
       "      <td>-4359.6484</td>\n",
       "      <td>0.6104</td>\n",
       "      <td>38</td>\n",
       "      <td>122784.2329</td>\n",
       "      <td>7771.982946</td>\n",
       "      <td>12456.6605</td>\n",
       "      <td>65911.4244</td>\n",
       "      <td>53454.7638</td>\n",
       "      <td>55</td>\n",
       "      <td>201152.3179</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  block_date  deposit_tx_count  deposit_withdrawal_ratio  \\\n",
       "0 2022-12-24                11                    1.5554   \n",
       "1 2022-12-25                10                    4.4874   \n",
       "2 2022-12-26                 8                    0.1890   \n",
       "\n",
       "   exchange_volume_ratio  mega_whale_ratio  mega_whale_tx_count  \\\n",
       "0                 0.2899            0.9475                   36   \n",
       "1                 0.6327            1.0000                   36   \n",
       "2                 0.3896            0.9751                   50   \n",
       "\n",
       "   mega_whale_volume_eth  net_flow_ma7  non_exchange_ratio  \\\n",
       "0            108354.7154    -7203.9190              0.7101   \n",
       "1            147540.1401   -33266.8544              0.3673   \n",
       "2            196152.9223    -4359.6484              0.6104   \n",
       "\n",
       "   non_exchange_tx_count  non_exchange_volume_eth  std_whale_tx_size_eth  \\\n",
       "0                     24               81206.9408            3279.562931   \n",
       "1                     18               54184.9701            8106.493990   \n",
       "2                     38              122784.2329            7771.982946   \n",
       "\n",
       "   whale_exchange_deposits_eth  whale_exchange_withdrawals_eth  \\\n",
       "0                   20175.0838                      12971.1648   \n",
       "1                   76342.4799                      17012.6900   \n",
       "2                   12456.6605                      65911.4244   \n",
       "\n",
       "   whale_net_exchange_flow_eth  whale_tx_count  whale_volume_eth  \\\n",
       "0                   -7203.9190              42       114353.1894   \n",
       "1                  -59329.7899              36       147540.1401   \n",
       "2                   53454.7638              55       201152.3179   \n",
       "\n",
       "   withdrawal_tx_count  \n",
       "0                    7  \n",
       "1                    8  \n",
       "2                    9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Dune Data (Whales & Market Intent)\n",
    "\n",
    "# %%\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING DUNE DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "datasets = {}\n",
    "for name, (qid, cache, output) in QUERIES.items():\n",
    "    print(f\"\\n{name.upper()}\")\n",
    "    print(\"-\"*40)\n",
    "    datasets[name] = fetch_dune_incremental(qid, cache)\n",
    "    datasets[name].to_csv(output, index=False)\n",
    "    print(f\"üíæ Saved to {output}\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "df_whales = datasets[\"whales\"]\n",
    "df_market_intent = datasets[\"market_intent\"]\n",
    "\n",
    "print(f\"\\n‚úÖ Dune Data Loaded:\")\n",
    "print(f\"   ‚Ä¢ Whales: {len(df_whales)} rows\")\n",
    "print(f\"   ‚Ä¢ Market Intent: {len(df_market_intent)} rows\")\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\nüìä Whales Sample:\")\n",
    "display(df_whales.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce1ff5",
   "metadata": {},
   "source": [
    "- Coingecko Price Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d762644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_coingecko_price_chunked(cg_id, start_date, end_date, api_key, chunk_days=30):\n",
    "    \"\"\"\n",
    "    Fetch historical price data from CoinGecko in chunks.\n",
    "    \n",
    "    Using 30-day chunks for reliability with Pro API.\n",
    "    \"\"\"\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Use Pro API URL if API key is provided\n",
    "    base_url = \"https://pro-api.coingecko.com/api/v3\" if api_key else \"https://api.coingecko.com/api/v3\"\n",
    "    \n",
    "    all_data = []\n",
    "    current_start = start_dt\n",
    "    \n",
    "    while current_start < end_dt:\n",
    "        current_end = min(current_start + timedelta(days=chunk_days), end_dt)\n",
    "        \n",
    "        from_ts = int(current_start.timestamp())\n",
    "        to_ts = int(current_end.timestamp())\n",
    "        \n",
    "        url = f\"{base_url}/coins/{cg_id}/market_chart/range\"\n",
    "        params = {\"vs_currency\": \"usd\", \"from\": from_ts, \"to\": to_ts}\n",
    "        headers = {\"x-cg-pro-api-key\": api_key} if api_key else {}\n",
    "        \n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(url, params=params, headers=headers)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                data = response.json()\n",
    "                prices = data.get(\"prices\", [])\n",
    "                \n",
    "                if prices:\n",
    "                    all_data.extend(prices)\n",
    "                \n",
    "                print(f\"   üì• {current_start.date()} ‚Üí {current_end.date()} ({len(prices)} points)\")\n",
    "                \n",
    "                # Rate limiting\n",
    "                time.sleep(0.3)\n",
    "                break  # Success, exit retry loop\n",
    "                \n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    wait_time = 60 * (attempt + 1)\n",
    "                    print(f\"   ‚ö†Ô∏è  Rate limited. Waiting {wait_time}s... (attempt {attempt+1}/{max_retries})\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    # Print detailed error info\n",
    "                    print(f\"   ‚ùå Error: {e.response.status_code} - {e.response.text}\")\n",
    "                    print(f\"   URL: {url}\")\n",
    "                    print(f\"   Params: {params}\")\n",
    "                    \n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"   Retrying in 5s... (attempt {attempt+1}/{max_retries})\")\n",
    "                        time.sleep(5)\n",
    "                    else:\n",
    "                        raise\n",
    "        \n",
    "        current_start = current_end + timedelta(days=1)\n",
    "    \n",
    "    if not all_data:\n",
    "        return pd.DataFrame(columns=[\"date\", \"price\"])\n",
    "    \n",
    "    df = pd.DataFrame(all_data, columns=[\"timestamp\", \"price\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\").dt.date\n",
    "    df = df.groupby(\"date\")[\"price\"].mean().reset_index()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    symbol = cg_id.upper()\n",
    "    print(f\"üìà {symbol}: {len(df)} days | ${df['price'].min():.0f} - ${df['price'].max():.0f}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0079fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cached_price(symbol):\n",
    "    \"\"\"Load price data from cache.\"\"\"\n",
    "    path = f\"{PRICE_CACHE_DIR}/{symbol}.csv\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_price_cache(symbol, df):\n",
    "    \"\"\"Save price data to cache.\"\"\"\n",
    "    path = f\"{PRICE_CACHE_DIR}/{symbol}.csv\"\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df.sort_values(\"date\").drop_duplicates(\"date\").to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac554ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_data_incremental(symbol, cg_id, start_date, end_date):\n",
    "    \n",
    "    cached = load_cached_price(symbol)\n",
    "    \n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "    today = pd.Timestamp(datetime.utcnow().date())\n",
    "    yesterday = today - timedelta(days=1)\n",
    "    \n",
    "    if cached is None:\n",
    "        print(f\"üì¶ No cache for {symbol.upper()}. Fetching full range...\")\n",
    "        fetch_start = start_date\n",
    "        base_df = pd.DataFrame()\n",
    "    else:\n",
    "        last_cached_date = pd.Timestamp(cached[\"date\"].max())\n",
    "        \n",
    "        # Check if we have data through yesterday\n",
    "        if last_cached_date >= yesterday:\n",
    "            print(f\"‚úÖ {symbol.upper()} cache up-to-date (through {last_cached_date.date()})\")\n",
    "            return cached\n",
    "        \n",
    "        fetch_start = last_cached_date + timedelta(days=1)\n",
    "        base_df = cached\n",
    "        print(f\"üîÑ Updating {symbol.upper()}: {fetch_start.date()} ‚Üí {yesterday.date()}\")\n",
    "    \n",
    "    # Cap end_date at yesterday (we predict next day, so only need up to yesterday)\n",
    "    end_date = min(end_date, yesterday)\n",
    "    \n",
    "    # Fetch historical data with chunking\n",
    "    if fetch_start <= end_date:\n",
    "        new_data = fetch_coingecko_price_chunked(\n",
    "            cg_id,\n",
    "            fetch_start.strftime(\"%Y-%m-%d\"),\n",
    "            end_date.strftime(\"%Y-%m-%d\"),\n",
    "            COINGECKO_API_KEY\n",
    "        )\n",
    "        \n",
    "        df_new = new_data.rename(columns={\"price\": f\"{symbol}_price\"})\n",
    "        df_all = pd.concat([base_df, df_new], ignore_index=True)\n",
    "        save_price_cache(symbol, df_all)\n",
    "    else:\n",
    "        df_all = base_df\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8635f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Date range: 2022-09-15 ‚Üí 2025-12-22\n",
      "   (Includes 100-day buffer for indicators)\n",
      "\n",
      "========================================\n",
      "ETHEREUM (ETH)\n",
      "========================================\n",
      "üîÑ Updating ETH: 2025-12-22 ‚Üí 2025-12-22\n",
      "üíæ ETH prices: 1156 days\n",
      "\n",
      "========================================\n",
      "BITCOIN (BTC)\n",
      "========================================\n",
      "üîÑ Updating BTC: 2025-12-22 ‚Üí 2025-12-22\n",
      "üíæ BTC prices: 1156 days\n"
     ]
    }
   ],
   "source": [
    "whales_min = df_whales['block_date'].min()\n",
    "whales_max = df_whales['block_date'].max()\n",
    "intent_min = df_market_intent['block_date'].min()\n",
    "intent_max = df_market_intent['block_date'].max()\n",
    "\n",
    "# Add 100-day buffer for technical indicators\n",
    "min_date = min(whales_min, intent_min) - timedelta(days=100)\n",
    "max_date = max(whales_max, intent_max)\n",
    "\n",
    "print(f\"\\nüìÖ Date range: {min_date.date()} ‚Üí {max_date.date()}\")\n",
    "print(f\"   (Includes 100-day buffer for indicators)\")\n",
    "\n",
    "# Fetch ETH prices\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"ETHEREUM (ETH)\")\n",
    "print(f\"{'='*40}\")\n",
    "df_eth = get_price_data_incremental(\"eth\", \"ethereum\", min_date, max_date)\n",
    "print(f\"üíæ ETH prices: {len(df_eth)} days\")\n",
    "\n",
    "# Fetch BTC prices\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"BITCOIN (BTC)\")\n",
    "print(f\"{'='*40}\")\n",
    "df_btc = get_price_data_incremental(\"btc\", \"bitcoin\", min_date, max_date)\n",
    "print(f\"üíæ BTC prices: {len(df_btc)} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5740402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Loaded Datasets:\n",
      "   ‚Ä¢ Whales Features:      1095 rows\n",
      "   ‚Ä¢ Market Intent:        1095 rows\n",
      "   ‚Ä¢ ETH Prices:           1156 rows\n",
      "   ‚Ä¢ BTC Prices:           1156 rows\n",
      "\n",
      "üìÖ Date Ranges:\n",
      "   ‚Ä¢ Whales:        2022-12-24 ‚Üí 2025-12-22\n",
      "   ‚Ä¢ Market Intent: 2022-12-24 ‚Üí 2025-12-22\n",
      "   ‚Ä¢ ETH:           2022-09-15 ‚Üí 2025-12-21\n",
      "   ‚Ä¢ BTC:           2022-09-15 ‚Üí 2025-12-21\n",
      "\n",
      "‚úÖ All data ready for feature engineering and modeling!\n",
      "\n",
      "============================================================\n",
      "ETH PRICE SAMPLE\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>eth_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>2025-12-17</td>\n",
       "      <td>2906.573711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2025-12-18</td>\n",
       "      <td>2853.067689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>2025-12-19</td>\n",
       "      <td>2935.880471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2025-12-20</td>\n",
       "      <td>2979.478368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2025-12-21</td>\n",
       "      <td>2980.317996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    eth_price\n",
       "1151 2025-12-17  2906.573711\n",
       "1152 2025-12-18  2853.067689\n",
       "1153 2025-12-19  2935.880471\n",
       "1154 2025-12-20  2979.478368\n",
       "1155 2025-12-21  2980.317996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BTC PRICE SAMPLE\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>btc_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>2025-12-17</td>\n",
       "      <td>86887.683596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>2025-12-18</td>\n",
       "      <td>86679.145619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>2025-12-19</td>\n",
       "      <td>87362.632014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2025-12-20</td>\n",
       "      <td>88174.588995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>2025-12-21</td>\n",
       "      <td>88260.199788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     btc_price\n",
       "1151 2025-12-17  86887.683596\n",
       "1152 2025-12-18  86679.145619\n",
       "1153 2025-12-19  87362.632014\n",
       "1154 2025-12-20  88174.588995\n",
       "1155 2025-12-21  88260.199788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"\\nüìä Loaded Datasets:\")\n",
    "print(f\"   ‚Ä¢ Whales Features:     {len(df_whales):>5} rows\")\n",
    "print(f\"   ‚Ä¢ Market Intent:       {len(df_market_intent):>5} rows\")\n",
    "print(f\"   ‚Ä¢ ETH Prices:          {len(df_eth):>5} rows\")\n",
    "print(f\"   ‚Ä¢ BTC Prices:          {len(df_btc):>5} rows\")\n",
    "\n",
    "print(f\"\\nüìÖ Date Ranges:\")\n",
    "print(f\"   ‚Ä¢ Whales:        {df_whales['block_date'].min().date()} ‚Üí {df_whales['block_date'].max().date()}\")\n",
    "print(f\"   ‚Ä¢ Market Intent: {df_market_intent['block_date'].min().date()} ‚Üí {df_market_intent['block_date'].max().date()}\")\n",
    "print(f\"   ‚Ä¢ ETH:           {df_eth['date'].min().date()} ‚Üí {df_eth['date'].max().date()}\")\n",
    "print(f\"   ‚Ä¢ BTC:           {df_btc['date'].min().date()} ‚Üí {df_btc['date'].max().date()}\")\n",
    "\n",
    "print(\"\\n‚úÖ All data ready for feature engineering and modeling!\")\n",
    "\n",
    "# Display samples\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ETH PRICE SAMPLE\")\n",
    "print(f\"{'='*60}\")\n",
    "display(df_eth.tail(5))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BTC PRICE SAMPLE\")\n",
    "print(f\"{'='*60}\")\n",
    "display(df_btc.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0b93a",
   "metadata": {},
   "source": [
    "- Feature Engineering from version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb6736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è Engineering features...\n",
      "‚úÖ Features created: 65 total columns\n",
      "‚úÖ Final dataset: 1095 rows\n",
      "   Dropped 0 rows (NaN target)\n",
      "üíæ Saved: whale_prices_ml_ready.csv\n"
     ]
    }
   ],
   "source": [
    "def add_price_features(df, price_col, prefix):\n",
    "    \"\"\"Add price-based ML features\"\"\"\n",
    "    df = df.sort_values('block_date').reset_index(drop=True)\n",
    "    \n",
    "    # Returns\n",
    "    df[f'{prefix}_daily_return'] = df[price_col].pct_change()\n",
    "    df[f'{prefix}_log_return'] = np.log(df[price_col] / df[price_col].shift(1))\n",
    "    \n",
    "    # Moving averages\n",
    "    df[f'{prefix}_ma7'] = df[price_col].rolling(7, min_periods=1).mean()\n",
    "    df[f'{prefix}_ma30'] = df[price_col].rolling(30, min_periods=1).mean()\n",
    "    \n",
    "    # Momentum\n",
    "    df[f'{prefix}_vs_ma7'] = df[price_col] / df[f'{prefix}_ma7']\n",
    "    df[f'{prefix}_vs_ma30'] = df[price_col] / df[f'{prefix}_ma30']\n",
    "    \n",
    "    # Volatility\n",
    "    df[f'{prefix}_vol7'] = df[f'{prefix}_daily_return'].rolling(7, min_periods=1).std()\n",
    "    df[f'{prefix}_vol30'] = df[f'{prefix}_daily_return'].rolling(30, min_periods=1).std()\n",
    "    \n",
    "    # Returns\n",
    "    df[f'{prefix}_ret7d'] = df[price_col].pct_change(7)\n",
    "    df[f'{prefix}_ret30d'] = df[price_col].pct_change(30)\n",
    "    \n",
    "    # RSI\n",
    "    returns = df[f'{prefix}_daily_return']\n",
    "    gains = returns.where(returns > 0, 0).rolling(14, min_periods=1).mean()\n",
    "    losses = -returns.where(returns < 0, 0).rolling(14, min_periods=1).mean()\n",
    "    rs = gains / (losses + 1e-10)\n",
    "    df[f'{prefix}_rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Lags\n",
    "    for lag in [1, 3, 7]:\n",
    "        df[f'{prefix}_ret_lag{lag}'] = df[f'{prefix}_daily_return'].shift(lag)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_correlation_features(df):\n",
    "    \"\"\"Add ETH-BTC correlation features\"\"\"\n",
    "    df['eth_btc_ratio'] = df['eth_price'] / df['btc_price']\n",
    "    df['eth_btc_ratio_ma7'] = df['eth_btc_ratio'].rolling(7, min_periods=1).mean()\n",
    "    df['eth_btc_corr_30d'] = df['eth_daily_return'].rolling(30, min_periods=20).corr(df['btc_daily_return'])\n",
    "    df['eth_outperformance'] = df['eth_daily_return'] - df['btc_daily_return']\n",
    "    return df\n",
    "\n",
    "def create_target(df):\n",
    "    \"\"\"Create target: next day price direction\"\"\"\n",
    "    df['next_day_return'] = df['eth_price'].pct_change().shift(-1)\n",
    "    df['next_day_price_direction'] = (df['next_day_return'] > 0).astype(int)\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "print(\"\\n‚öôÔ∏è Engineering features...\")\n",
    "\n",
    "df_merged = add_price_features(df_merged, 'eth_price', 'eth')\n",
    "df_merged = add_price_features(df_merged, 'btc_price', 'btc')\n",
    "df_merged = add_correlation_features(df_merged)\n",
    "df_merged = create_target(df_merged)\n",
    "\n",
    "print(f\"‚úÖ Features created: {len(df_merged.columns)} total columns\")\n",
    "\n",
    "# Drop rows with NaN target\n",
    "df_final = df_merged.dropna(subset=['next_day_price_direction']).copy()\n",
    "\n",
    "print(f\"‚úÖ Final dataset: {len(df_final)} rows\")\n",
    "print(f\"   Dropped {len(df_merged) - len(df_final)} rows (NaN target)\")\n",
    "\n",
    "# Save\n",
    "df_final.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"üíæ Saved: {OUTPUT_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
